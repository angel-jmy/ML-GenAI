{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf52ecb-2e04-4532-b519-78d0fb6a8c0c",
   "metadata": {},
   "source": [
    "## Multiple Choice Questions\n",
    "\n",
    "**1. What is the main difference between Chat models and Text models?** C  \n",
    "A. Chat models are newer  \n",
    "B. Chat models return data in a different format than Text models  \n",
    "C. Chat models can include role prompts in the message  \n",
    "D. Text models can transmit multiple messages at once  \n",
    "\n",
    "**2. Which of the following statements about OpenAI Assistant Threads is correct?** B\n",
    "A. A Thread can only contain one Assistant message  \n",
    "B. A Thread automatically manages the context window to ensure it does not exceed the model’s context length limit  \n",
    "C. A Thread will automatically delete after 24 hours  \n",
    "D. You cannot add new messages to an already created Thread  \n",
    "\n",
    "**3. When adding a Function to Assistants, what needs to be provided?** C  \n",
    "A. The function’s Python code  \n",
    "B. The function’s JavaScript code  \n",
    "C. The function’s JSON description  \n",
    "D. The function’s C++ code  \n",
    "\n",
    "**4. Which of the following operations is possible when using the Code Interpreter for data analysis?** ABC  \n",
    "A. Data slicing  \n",
    "B. Data filtering  \n",
    "C. Data sorting  \n",
    "D. Data encryption  \n",
    "\n",
    "**5. What abilities do large language models have in data analysis?** ABCD  \n",
    "A. Generate text summaries  \n",
    "B. Read data  \n",
    "C. Create visualizations  \n",
    "D. Generate meaningful insights  \n",
    "\n",
    "**6. What steps can be included in constructing a local document Q&A system?** ABCDE  \n",
    "A. Loading: The document loader loads documents into a format that LangChain can read  \n",
    "B. Splitting: The text splitter splits documents into specified-size segments, i.e., \"document blocks\" or \"document pieces\"  \n",
    "C. Storage: The split \"document blocks\" are stored in vector databases as \"embedded pieces\"  \n",
    "D. Retrieval: The system retrieves the split documents from storage  \n",
    "E. Synthesis: The question and similar embedded pieces are passed to the language model to generate an answer  \n",
    "\n",
    "**7. Which of the following are the basic principles of prompt engineering mentioned in the document?** ABD  \n",
    "A. Write clear instructions  \n",
    "B. Provide reference materials  \n",
    "C. Increase the model’s training data volume  \n",
    "D. Divide and simplify  \n",
    "\n",
    "**8. What does the “Few-Shot Learning” concept in prompt engineering refer to?** B  \n",
    "A. Learning from a large number of samples  \n",
    "B. Learning and generalizing new tasks from a very small number of data samples  \n",
    "C. Learning from only one sample  \n",
    "D. Learning new tasks without any samples  \n",
    "\n",
    "**9. If you want to implement few-shot prompting, which prompt template should you choose?** C  \n",
    "A. PromptTemplate  \n",
    "B. ChatPromptTemplate  \n",
    "C. FewShotPromptTemplate  \n",
    "D. PipelinePromptTemplate  \n",
    "\n",
    "**10. What specific content should be included in a CoT prompt template?** ABC  \n",
    "A. Description of the AI’s role and goal  \n",
    "B. Explanation of the chain of thought  \n",
    "C. Examples that follow the chain of thought  \n",
    "D. Search for multiple thinking paths  \n",
    "\n",
    "**11. Scenario: You are building a smart writing assistant that can generate an article based on user-provided prompts. You are using GPT-3 as the language model. The output of GPT-3 is raw text, and you need to convert it into structured JSON format so that your application can further process it.**  \n",
    "**Question: In this scenario, which LangChain output parser would you choose?** AC  \n",
    "A. PydanticOutputParser  \n",
    "B. XMLOutputParser  \n",
    "C. StructuredOutputParser  \n",
    "D. CommaSeparatedListOutputParser  \n",
    "\n",
    "**12. Which type of memory can both remember summaries of conversations from many turns ago and retain the raw content from the most recent turns?** D  \n",
    "A. ConversationBufferMemory  \n",
    "B. ConversationBufferWindowMemory  \n",
    "C. ConversationSummaryMemory  \n",
    "D. ConversationSummaryBufferMemory  \n",
    "\n",
    "**13. In what aspect does GPT-4 have significant capability improvements compared to previous GPT models?** C  \n",
    "A. English text processing  \n",
    "B. Coding tasks  \n",
    "C. Audio processing  \n",
    "D. Image recognition  \n",
    "\n",
    "**14. The working principle of RAG can be summarized as which of the following steps?** ABC  \n",
    "A. Retrieval: The model first uses a retrieval system to find relevant documents or paragraphs from a large document collection for the given input (question)  \n",
    "B. Context Encoding: After finding relevant documents or paragraphs, the model encodes them along with the original input (question)  \n",
    "C. Generation: The model generates an output (answer) using the encoded context information  \n",
    "D. Check: Use the search function to verify the accuracy of the final information  \n",
    "\n",
    "**15. Which type of agent is considered a simulation agent (role-playing in a simulated environment, attempting to simulate specific scenarios or behaviors)?** C  \n",
    "A. AutoGPT  \n",
    "B. BabyAGI  \n",
    "C. CAMEL  \n",
    "D. Hugging\n",
    "\n",
    "**16. Which of the following statements is correct?** ACD  \n",
    "A. AutoGPT can automatically link multiple tasks to achieve a large goal  \n",
    "B. BabyAGI is characterized by integrating multimodal perception capabilities to handle multiple AI tasks  \n",
    "C. HuggingGPT selects appropriate expert models from Hugging Face to execute tasks  \n",
    "D. AutoGPT, BabyAGI, and HuggingGPT are all self-driven (autonomous) agents  \n",
    "\n",
    "**17. When fine-tuning using the OpenAI API, how is the fine-tuning job cost estimated?** B  \n",
    "A. Basic cost per 1k Tokens × Token count in the input file  \n",
    "B. Basic cost per 1k Tokens × Token count in the input file × Number of training Epochs  \n",
    "C. Token count in the input file × Number of training Epochs  \n",
    "D. Token count in the input file * Number of training Epochs  \n",
    "\n",
    "**18. What is the main effect achieved by quantization technology?** C  \n",
    "A. Improve model accuracy  \n",
    "B. Increase model parameter size  \n",
    "C. Reduce model size  \n",
    "D. Increase training time  \n",
    "\n",
    "**19. Which architecture does the Sora model use?** C  \n",
    "A. U-Net  \n",
    "B. GAN  \n",
    "C. Diffusion Transformer (DiT)  \n",
    "D. RNN  \n",
    "\n",
    "**20. Which of the following are examples of multimodal interaction tasks?** ABCD  \n",
    "A. Text to speech  \n",
    "B. Speech to text  \n",
    "C. Text to image  \n",
    "D. Image to video  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ea991-fd22-4b1d-918d-00fcf5cce744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe24ed-e1fb-4842-a192-ec6aa72f6b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb312666-7ed1-4e6c-978a-7e59615212bc",
   "metadata": {},
   "source": [
    "## Practical Questions\n",
    "\n",
    "**Project**: Internal Employee Knowledge Base Q&A System.\n",
    "\n",
    "**Project Description**: \"Floral\" is a large-scale online flower sales platform with its own business processes and standards, as well as Standard Operating Procedure (SOP) manuals for employees. Relevant information is shared during new employee onboarding training. However, this information is scattered across various internal websites and directories of the HR department, making it inconvenient to access at times. Additionally, employees may struggle to find the desired content promptly due to lengthy documents, and sometimes, company policies are updated while employees still have outdated document versions.\n",
    "\n",
    "To address these needs, we will develop a \"Doc-QA\" system based on various internal knowledge manuals.\n",
    "\n",
    "This question-and-answer system will understand employees' inquiries and provide precise answers based on the latest employee manuals.\n",
    "\n",
    "**Prepared Data:**\n",
    "\n",
    "Internal data includes various files in PDF, Word, and TXT formats. These have already been provided.\n",
    "\n",
    "LangChain  \n",
    "1. Data Sources  \n",
    "2. LLM app  \n",
    "3. Use-Cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c984cfc-432b-4004-bf35-6ede931b860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install required packages\n",
    "# !pip install langchain openai faiss-cpu unstructured pypdf python-docx\n",
    "# !pip install -U langchain langchain-community\n",
    "# !pip install unstructured pdfminer.six python-docx faiss-cpu\n",
    "# !pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e15988-96b0-47e0-a290-8b7cac85cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredWordDocumentLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "base_path = 'docs'\n",
    "\n",
    "# Loop through files and load based on file extension\n",
    "for file in os.listdir(base_path):\n",
    "    file_path = os.path.join(base_path, file)\n",
    "\n",
    "    if file.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file.endswith(\".docx\"):\n",
    "        loader = UnstructuredWordDocumentLoader(file_path)\n",
    "    elif file.endswith(\".txt\"):\n",
    "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    else:\n",
    "        continue  # Skip unsupported file types\n",
    "\n",
    "    docs = loader.load()\n",
    "    all_docs.extend(docs)\n",
    "\n",
    "    \n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(all_docs)\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", openai_api_key=api_key)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "\n",
    "vectorstore.save_local(\"flower_doc_qa_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47253a33-20fc-4251-ab07-cbd9fed1496d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f919b1-eadb-4ad8-83b9-d6fcf002ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

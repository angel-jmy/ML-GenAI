{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fc9d7e-1e7b-4143-86b1-cea2afa7cec0",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/how_to/#callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f082408-2211-4193-b3a4-0c50b6392949",
   "metadata": {},
   "source": [
    "# Attach Callback to a Runnable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b234909a-6475-44d5-ad65-5d91f7004292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afab1ab3-d0f9-4c58-857f-a6a4ae395b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LoggingHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain ChatPromptTemplate started\n",
      "Chain ended, outputs: messages=[HumanMessage(content='What is 1 + 2?', additional_kwargs={}, response_metadata={})]\n",
      "Chat model started\n",
      "Chat model ended, response: generations=[[ChatGeneration(message=AIMessage(content='1 + 2 = 3.', additional_kwargs={}, response_metadata={'id': 'msg_01SVmuvUF4AfWKDq7rzHwSwh', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 16, 'output_tokens': 14, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-haiku-20240307'}, id='run--38c9a255-199b-453e-962f-5e412b23089c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 14, 'total_tokens': 30, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}), text='1 + 2 = 3.')]] llm_output={'id': 'msg_01SVmuvUF4AfWKDq7rzHwSwh', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 16, 'output_tokens': 14, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-haiku-20240307'} run=None type='LLMResult'\n",
      "Chain ended, outputs: content='1 + 2 = 3.' additional_kwargs={} response_metadata={'id': 'msg_01SVmuvUF4AfWKDq7rzHwSwh', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 16, 'output_tokens': 14, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-haiku-20240307'} id='run--38c9a255-199b-453e-962f-5e412b23089c-0' usage_metadata={'input_tokens': 16, 'output_tokens': 14, 'total_tokens': 30, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1 + 2 = 3.', additional_kwargs={}, response_metadata={'id': 'msg_01SVmuvUF4AfWKDq7rzHwSwh', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 16, 'output_tokens': 14, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-haiku-20240307'}, id='run--38c9a255-199b-453e-962f-5e412b23089c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 14, 'total_tokens': 30, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import LLMResult\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class LoggingHandler(BaseCallbackHandler):\n",
    "    def on_chat_model_start(\n",
    "        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs\n",
    "    ) -> None:\n",
    "        print(\"Chat model started\")\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
    "        print(f\"Chat model ended, response: {response}\")\n",
    "\n",
    "    def on_chain_start(\n",
    "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs\n",
    "    ) -> None:\n",
    "        print(f\"Chain {serialized.get('name')} started\")\n",
    "\n",
    "    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:\n",
    "        print(f\"Chain ended, outputs: {outputs}\")\n",
    "\n",
    "callbacks = [LoggingHandler()]\n",
    "# llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is 1 + {number}?\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"number\": \"2\"}, config={\"callbacks\": callbacks})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a48037-6037-4a97-949f-c23729de2be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

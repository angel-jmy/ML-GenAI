{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea9e29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "d_k = 64\n",
    "d_v = 64\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()        \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) \n",
    "        scores.masked_fill_(attn_mask, -1e9) \n",
    "        weights = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(weights, V)\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc173797",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_embedding = 512\n",
    "n_heads = 8\n",
    "batch_size = 3\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = nn.Linear(d_embedding, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_embedding, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_embedding, d_v * n_heads)\n",
    "        self.linear = nn.Linear(n_heads * d_v, d_embedding)\n",
    "        self.layer_norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):      \n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)        \n",
    "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
    "        context, weights = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) \n",
    "        output = self.linear(context)\n",
    "        output = self.layer_norm(output + residual)\n",
    "        return output, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea0d367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_embedding, out_channels=2048, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=2048, out_channels=d_embedding, kernel_size=1)\n",
    "        self.layer_norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, inputs):   \n",
    "        residual = inputs\n",
    "        output = nn.ReLU()(self.conv1(inputs.transpose(1, 2)))\n",
    "        output = self.conv2(output).transpose(1, 2)\n",
    "        output = self.layer_norm(output + residual)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1dab244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_sin_enc_table(n_position, embedding_dim):\n",
    "    sinusoid_table = np.zeros((n_position, embedding_dim))    \n",
    "    for pos_i in range(n_position):\n",
    "        for hid_j in range(embedding_dim):\n",
    "            angle = pos_i / np.power(10000, 2 * (hid_j // 2) / embedding_dim)\n",
    "            sinusoid_table[pos_i, hid_j] = angle    \n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    return torch.FloatTensor(sinusoid_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1f32613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)\n",
    "    pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k) \n",
    "    return pad_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2cb5167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequent_mask(seq):\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
    "    subsequent_mask = torch.from_numpy(subsequent_mask).byte()\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8bfb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention()\n",
    "        self.feed_forward = PoswiseFeedForwardNet()\n",
    "        self.norm1 = nn.LayerNorm(d_embedding)\n",
    "        self.norm2 = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, dec_inputs, attn_mask=None):\n",
    "        attn_output, _ = self.self_attn(dec_inputs, dec_inputs, dec_inputs, attn_mask)\n",
    "\n",
    "        norm1_outputs = self.norm1(dec_inputs + attn_output)\n",
    "\n",
    "        ff_outputs = self.feed_forward(norm1_outputs)\n",
    "        \n",
    "        dec_outputs = self.norm2(norm1_outputs + ff_outputs)\n",
    "        return dec_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33d35d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 6\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(vocab_size, d_embedding)\n",
    "        self.pos_emb = nn.Embedding(max_seq_len, d_embedding)       \n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, dec_inputs):        \n",
    "        positions = torch.arange(len(dec_inputs), device=dec_inputs.device).unsqueeze(-1)      \n",
    "        inputs_embedding = self.src_emb(dec_inputs) + self.pos_emb(positions)      \n",
    "        attn_mask = get_attn_subsequent_mask(inputs_embedding).to(device)    \n",
    "        for layer in self.layers:\n",
    "            dec_outputs = layer(inputs_embedding, attn_mask)\n",
    "        return dec_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82e6acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len):\n",
    "        super(GPT, self).__init__()\n",
    "        self.decoder = Decoder(vocab_size, max_seq_len)\n",
    "        self.projection = nn.Linear(d_embedding, vocab_size)\n",
    "\n",
    "    def forward(self, dec_inputs):        \n",
    "        dec_outputs = self.decoder(dec_inputs)\n",
    "        logits = self.projection(dec_outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08930c4c",
   "metadata": {},
   "source": [
    "##  Building Dataset and DataLoader with WikiText2\n",
    "pip install torchtext  0.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 : Download the corpus and build the vocabulary\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "valid_iter = WikiText2(split='valid')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for item in data_iter:\n",
    "        yield tokenizer(item)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), \n",
    "                                  specials=[\"<pad>\", \"<sos>\", \"<eos>\"])\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print(\"Vocabulary example (word to index):\", \n",
    "      {word: vocab[word] for word in [\"<pad>\", \"<sos>\", \"<eos>\", \"the\", \"apple\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33341df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 : Construct the pytorch dataset\n",
    "from torch.utils.data import Dataset\n",
    "max_seq_len = 256\n",
    "\n",
    "class WikiDataset(Dataset):\n",
    "    def __init__(self, data_iter, vocab, max_len=max_seq_len):\n",
    "        self.data = []        \n",
    "        for sentence in data_iter:\n",
    "            tokens = tokenizer(sentence)[:max_len - 2]\n",
    "            tokens = [vocab[\"<sos>\"]] + vocab(tokens) + [vocab[\"<eos>\"]]         \n",
    "            self.data.append(tokens)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)    \n",
    "    \n",
    "    def __getitem__(self, idx):       \n",
    "        source = self.data[idx][:-1]    \n",
    "        target = self.data[idx][1:]      \n",
    "        return torch.tensor(source), torch.tensor(target)\n",
    "\n",
    "train_dataset = WikiDataset(train_iter, vocab)\n",
    "valid_dataset = WikiDataset(valid_iter, vocab)\n",
    "print(f\"Dataset entries: {len(train_dataset)}\")\n",
    "sample_source, sample_target = train_dataset[100]\n",
    "print(f\"Input sequence tensor example: {sample_source}\")\n",
    "print(f\"Target sequence tensor example: {sample_target}\")\n",
    "decoded_source = ' '.join(vocab.lookup_tokens(sample_source.tolist()))\n",
    "decoded_target = ' '.join(vocab.lookup_tokens(sample_target.tolist()))\n",
    "print(f\"Input sequence example text: {decoded_source}\")\n",
    "print(f\"Target sequence example text: {decoded_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c61f26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 : Build the dataloader class.\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def pad_sequence(sequences, padding_value=0, length=None):\n",
    "    max_length = max(len(seq) for seq in sequences) if length is None else length    \n",
    "    result = torch.full((len(sequences), max_length), padding_value, dtype=torch.long)    \n",
    "\n",
    "    for i, seq in enumerate(sequences):\n",
    "        end = len(seq)\n",
    "        result[i, :end] = seq[:end]\n",
    "    return result\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sources, targets = zip(*batch)    \n",
    "\n",
    "    max_length = max(max(len(s) for s in sources), max(len(t) for t in targets))    \n",
    "\n",
    "    sources = pad_sequence(sources, padding_value=vocab[\"<pad>\"], length=max_length)\n",
    "    targets = pad_sequence(targets, padding_value=vocab[\"<pad>\"], length=max_length)    \n",
    "\n",
    "    return sources, targets\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                              shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                              shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54dd5b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = GPT(len(vocab), max_seq_len).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab[\"<pad>\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (source, target) in enumerate(train_dataloader):\n",
    "        inputs, targets = source.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1, len(vocab)), targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()        \n",
    "        if (batch_idx + 1) % 500 == 0:\n",
    "            print(f\"Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item()}\")   \n",
    "    epoch_loss /= len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {epoch_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c887288",
   "metadata": {},
   "source": [
    "#Evaluating the training process using the evaluation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1401a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Save the trained model\n",
    "# timestamp = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "# model_file_name = f\"trained_model_{timestamp}.pt\"\n",
    "# torch.save(model.state_dict(), model_file_name)\n",
    "# print(f\"Model saved as {model_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58ecd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c2a1101",
   "metadata": {},
   "source": [
    "gready search and beam_search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb185470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_beam_search(model, input_str, max_len=50, beam_width=5):\n",
    "    model.eval()\n",
    "    input_tokens = [vocab[token] for token in input_str.split()]\n",
    "    candidates = [(input_tokens, 0.0)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            new_candidates = []\n",
    "            for candidate, candidate_score in candidates:\n",
    "                inputs = torch.LongTensor(candidate).unsqueeze(0).to(device)\n",
    "                outputs = model(inputs)\n",
    "                logits = outputs[:, -1, :]\n",
    "\n",
    "                scores, next_tokens = torch.topk(logits, beam_width, dim=-1)\n",
    "                final_results = []\n",
    "                for score, next_token in zip(scores.squeeze(), next_tokens.squeeze()):\n",
    "                    new_candidate = candidate + [next_token.item()]\n",
    "                    new_score = candidate_score - score.item()\n",
    "                    if next_token.item() == vocab[\"<eos>\"]:\n",
    "                        final_results.append((new_candidate, new_score))\n",
    "                    else:\n",
    "                        new_candidates.append((new_candidate, new_score))\n",
    "\n",
    "            candidates = sorted(new_candidates, key=lambda x: x[1])[:beam_width]\n",
    "\n",
    "    best_candidate, _ = sorted(candidates, key=lambda x: x[1])[0]\n",
    "    output_str = \" \".join([vocab.get_itos()[token] for token in best_candidate if vocab.get_itos()[token] != \"<pad>\"])\n",
    "    return output_str\n",
    "\n",
    "model.load_state_dict(torch.load('trained_model_2024-...pt'))\n",
    "input_str = \"\"\n",
    "generated_text = generate_text_beam_search(model, input_str)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9dde51",
   "metadata": {},
   "source": [
    "HW:\n",
    "1.Use greedy search to complete the task\n",
    "2.Utilize the HuggingFace Transformers library to download new models for inference and compare their performance.\n",
    "3.Within LangChain,use both the HuggingFaceEndpoint and HuggingFace Pipline interfaces to call the currently most popular llm(meta-llama/Meta-Llama-3-8B,google/flan-t5-base)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd70780",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207f043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
